{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST Classifier Using Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will allow you to submit jobs to the [Watson Machine Learning (WML) service](https://www.ibm.com/cloud/machine-learning). \n",
    "\n",
    "At this point in the process you should have a working Watson Studio instance, alongside a Watson Machine Learning service, and a Cloud Object Storage bucket with the MNIST dataset files uploaded to it. From here we will cover steps 6-8 as defined in the Github, replicated here for clarity:\n",
    "\n",
    "1. Create a Watson Studio instance \n",
    "2. Add a Deep Learning project\n",
    "3. Hook up the Jupyter notebook\n",
    "4. Get the data, and upload it to your storage bucket\n",
    "5. Obtain the credentials for both COS and WML\n",
    "6. **Add your credentials to the template notebook**\n",
    "7. **Train the model- monitoring progress and results**\n",
    "8. **Deploy the model, and the test the endpoint**\n",
    "\n",
    "*If any of these requirements are sounding unfamiliar or confusing, then please check back on the [README.md](https://github.com/FarrandTom/wml-tf-mnist-classifier) of the Github repository.*\n",
    "\n",
    "Now that you have gotten this far, the basic workflow is as follows:\n",
    "\n",
    "                                 Download the model .zip\n",
    "            Download a .zip of your model files to this notebook. We are going to be\n",
    "            using Github to host our model files- as it allows for simple versioning\n",
    "            and control. There is nothing stopping you from using your Cloud Object \n",
    "            Storage bucket to hold the model.\n",
    "                                            |\n",
    "                                            ↓\n",
    "                                      Define your job\n",
    "            Define the credentials for your Cloud services; Watson Machine Learning,\n",
    "            Cloud Object Storage. During this step you will also define the parameters\n",
    "            for the job you would like to execute e.g. the deep learning framework, \n",
    "            version, and the command to start your job. \n",
    "                                            |\n",
    "                                            ↓\n",
    "                                          Train\n",
    "                                            |\n",
    "                                            ↓\n",
    "                                          Deploy\n",
    "                                            |\n",
    "                                            ↓\n",
    "                                        Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the model .zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install wget\n",
    "\n",
    "The first step of the process is to install wget in the virtual machine where your notebook is running. This will allow us to get the TensorFlow code from GitHub which we'll be using to perform the digit classification. \n",
    "\n",
    "To install wget - run the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Running setup.py bdist_wheel for wget ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Model Code\n",
    "\n",
    "If you wish to use own custom model, then simply replace the URL with you a link to your own .zip files. You could also modify the below code to link your Cloud Object Storage bucket, however that is outside the scope of this tutorial. \n",
    "\n",
    "If you are using a custom model, please pay attention to the note within the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "filename = 'tf-model.zip'\n",
    "url = 'MY GITHUB LINK HERE/tf-model.zip?raw=true'\n",
    "\n",
    "# NOTE: If you are re-running this code block again, having changed the model or adding your own custom model\n",
    "# be careful to ensure that your new model is the one which is truly downloaded.\n",
    "if not os.path.isfile( filename ): wget.download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Your Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you don't train the model by running the sample model-building code in your notebook directly. Instead, you submit a job to run the model-building code in a training run on Watson Machine Learning GPU-accelerated infrastructure.\n",
    "\n",
    "Submitting a training run requires two things:\n",
    "\n",
    "- A .zip file containing model-building code\n",
    "- Metadata\n",
    "\n",
    "From the previous steps we have taken we already have both of these pre-requisities. \n",
    "\n",
    "**A little note on terminology**: The model-building code and the metadata together are referred to as the *training definition*. You can think of this as being short for \"training run definition\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Watson Machine Learning Credentials\n",
    "\n",
    "Next, we shall define the `client` object. This will create a persistent connection to the Watson Machine Learning service we have provisioned- allowing us to define our model.\n",
    "\n",
    "Replace the `***` with the Watson Machine Learning credentials which we grabbed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_credentials = { \"url\"         : \"https://ibm-watson-ml.mybluemix.net\",\n",
    "                    \"username\"    : \"***\",\n",
    "                    \"password\"    : \"***\",\n",
    "                    \"instance_id\" : \"***\"\n",
    "                   }\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All model information is stored in the `client.repository` object. We define it below. \n",
    " \n",
    " Feel free to replace the `***` with your e-mail, however it will run regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "client.repository.DefinitionMetaNames.NAME              : \"python-client-tutorial_training-definition\",\n",
    "client.repository.DefinitionMetaNames.AUTHOR_EMAIL      : \"***\",\n",
    "client.repository.DefinitionMetaNames.FRAMEWORK_NAME    : \"tensorflow\",\n",
    "client.repository.DefinitionMetaNames.FRAMEWORK_VERSION : \"1.5\",\n",
    "client.repository.DefinitionMetaNames.RUNTIME_NAME      : \"python\",\n",
    "client.repository.DefinitionMetaNames.RUNTIME_VERSION   : \"3.5\",\n",
    "client.repository.DefinitionMetaNames.EXECUTION_COMMAND : \"python3 convolutional_network.py --trainImagesFile ${DATA_DIR}/train-images-idx3-ubyte.gz --trainLabelsFile ${DATA_DIR}/train-labels-idx1-ubyte.gz --testImagesFile ${DATA_DIR}/t10k-images-idx3-ubyte.gz --testLabelsFile ${DATA_DIR}/t10k-labels-idx1-ubyte.gz --learningRate 0.001 --trainingIters 20000\"\n",
    "}\n",
    "definition_details = client.repository.store_definition( \"tf-model.zip\", meta_props=metadata )\n",
    "definition_uid     = client.repository.get_definition_uid( definition_details )\n",
    "print( \"definition_uid: \", definition_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now connected to the Watson Machine learning service and subsequently *defined* your model. Meaning you have laid out scaffolding for how you want it to handle data, and execute. \n",
    "\n",
    "You are yet to define where the data you have uploaded to the Cloud Object Storage bucket is stored. This will be the next step..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Cloud Object Storage Credentials\n",
    "\n",
    "The `client.training` object contains the references to our training data and will be where the Watson Machine Learning service looks for the data we have uploaded into the Cloud Object Storage. \n",
    "\n",
    "Replace the `***` with the credentials corresponding to those we grabbed from the Cloud Object Storage bucket. \n",
    "\n",
    "**Note:** The `client.training` object does not specifiy any constraints on how your data should be laid out and setup. This is done in the model code which you define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "client.training.ConfigurationMetaNames.NAME         : \"python-client-tutorial_training-run\",\n",
    "client.training.ConfigurationMetaNames.AUTHOR_EMAIL : \"***\",\n",
    "client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCE : {\n",
    "   \"connection\" : { \n",
    "      \"endpoint_url\"      : \"***\",\n",
    "      \"access_key_id\"     : \"***\",\n",
    "      \"secret_access_key\" : \"***\"\n",
    "      },\n",
    "   \"source\" : { \n",
    "      \"bucket\" : \"***\",\n",
    "      },\n",
    "      \"type\" : \"s3\"\n",
    "   },\n",
    "client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE: {\n",
    "   \"connection\" : {\n",
    "      \"endpoint_url\"      : \"***\",\n",
    "      \"access_key_id\"     : \"***\",\n",
    "      \"secret_access_key\" : \"***\"\n",
    "      },\n",
    "      \"target\" : {\n",
    "         \"bucket\" : \"***\",\n",
    "      },\n",
    "      \"type\" : \"s3\"\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is then very simple for you to start the training run as you have now defined all of the necessary information to kick it off!\n",
    "\n",
    "Simply run the below block, which will then return to your run unique identifier of your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = client.training.run(definition_uid, meta_props=metadata)\n",
    "run_uid     = client.training.get_run_uid(run_details)\n",
    "print(\"run_uid: \", run_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor Progress\n",
    "\n",
    "To understand the status of the training job you can run, and subsequently re-run the following code block. It will tell you the status of the job, and any error codes produced (though more detailed logs can be found in the `.txt` files associated with each run). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.training.get_status(run_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Results alongside all other output from the model run, will be dropped into the results bucket of your Cloud Object Storage instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your trained model to classify new images only after the model has been deployed. \n",
    "\n",
    "Prior to deploying the model you must store your trained model in the Watson Machine Learning repository (you have already worked with this when defining your model, thus shouldn't be any new syntax). \n",
    "\n",
    "The below code block stores the trained model in your WML repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_name    = \"python-client-tutorial_model\"\n",
    "stored_model_details = client.repository.store_model(run_uid, stored_model_name)\n",
    "model_uid            = client.repository.get_model_uid(stored_model_details)\n",
    "print(\"model_uid: \", model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the freshly stored model by running the following block. It will provide an endpoint which you can call to generate inferences on new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name  = \"MNIST-Classifier\"\n",
    "deployment_desc  = \"Live deployment of the MNIST classifier\"\n",
    "deployment       = client.deployments.create(model_uid, deployment_name, deployment_desc)\n",
    "scoring_endpoint = client.deployments.get_scoring_url(deployment)\n",
    "print(\"scoring_endpoint: \", scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now submit new data to be evaluated by the trained model (a process known as inference). We will be calling our scoring endpoint and passing it a payload of a never before seen handwritten digit.\n",
    "\n",
    "Firstly, download the sample file of the digits \"5\" and \"4\" to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tf-mnist-test-payload.json'\n",
    "'MY GIT HUB BELOW'\n",
    "url = 'https://raw.githubusercontent.com/pmservice/wml-sample-models/master/tensorflow/hand-written-digit-recognition/test-data/tf-mnist-test-payload.json'\n",
    "if not os.path.isfile( filename ): wget.download( url )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll now load the contents of the file into a data structure recognised by the model scoring endpoint. In this instance that is JSON (a common data structure used in communications over HTTP connections). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('tf-mnist-test-payload.json') as data_file: test_data = json.load(data_file)\n",
    "payload = test_data['payload']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, calling the scoring endpoint!\n",
    "\n",
    "You should expect to get back: `{'values': [5, 4]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.score(scoring_endpoint, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's all folks! Hopefully you enjoyed the tutorial, learnt something and are feeling motivated to create some amazing models using Watson Machine Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
